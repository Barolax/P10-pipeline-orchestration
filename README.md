# P10 - Pipeline d'orchestration de flux de donnÃ©es

![Python](https://img.shields.io/badge/Python-3.11-blue)
![Docker](https://img.shields.io/badge/Docker-24.0-blue)
![Kestra](https://img.shields.io/badge/Kestra-latest-orange)
![Status](https://img.shields.io/badge/Status-Complete-success)


## ğŸ“‹ Contexte

Projet de mise en place d'un pipeline automatisÃ© pour **BottleNeck**, marchand de vins en ligne.

**Objectif :** Automatiser le processus mensuel d'analyse des ventes (actuellement manuel) pour :
- Calculer le chiffre d'affaires par produit
- Identifier les vins premium via analyse statistique (z-score)
- GÃ©nÃ©rer des rapports pour les responsables produits

---

## ğŸ¯ Livrables

- âœ… Workflow d'orchestration Kestra (`.yaml`)
- âœ… Pipeline automatisÃ© avec 14 tÃ¢ches
- âœ… 7 tests de validation automatisÃ©s
- âœ… Rapport CA en Excel (`.xlsx`)
- âœ… Extractions vins premium/ordinaires (`.csv`)
- âœ… Planification mensuelle (15 du mois Ã  9h)

---

## ğŸ—ï¸ Architecture
```
P10 - mise en place pipeline orchestration de flux/
â”œâ”€â”€ data_bottleneck/          # Fichiers sources (ERP, LIAISON, WEB)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ test_config.yaml      # Valeurs de rÃ©fÃ©rence pour tests
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb     # EDA complÃ¨te
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ nettoyage/           # Scripts SQL/Python de nettoyage + tests
â”‚   â”œâ”€â”€ fusion/              # Scripts fusion + tests
â”‚   â”œâ”€â”€ calculs/             # Scripts calcul CA + tests
â”‚   â””â”€â”€ premium/             # Script identification vins premium + tests
â”œâ”€â”€ kestra/
â”‚   â””â”€â”€ workflow.yaml        # Workflow d'orchestration
â”œâ”€â”€ diagrams/
â”‚   â””â”€â”€ P10.drawio.png       # Logigramme du pipeline
â”œâ”€â”€ Dockerfile               # Image Docker personnalisÃ©e
â””â”€â”€ requirements.txt
```

---

## ğŸ› ï¸ Technologies

- **Orchestration :** Kestra
- **Conteneurisation :** Docker
- **Base de donnÃ©es :** DuckDB (in-memory)
- **Langage :** Python 3.11, SQL
- **BibliothÃ¨ques :** pandas, scipy, openpyxl, pyyaml
- **Format d'Ã©change :** Parquet

---

## ğŸ“Š Workflow

Le pipeline comprend **14 tÃ¢ches** organisÃ©es en DAG :

### 1. Nettoyage (5 tÃ¢ches)
- `nettoyage-complet` : Suppression valeurs manquantes + dÃ©doublonnage
- `test-nettoyage-erp` : Validation 825 lignes
- `test-nettoyage-liaison` : Validation 825 lignes
- `test-nettoyage-web-clean` : Validation 1428 lignes
- `test-nettoyage-web-dedup` : Validation 714 lignes

### 2. Fusion (2 tÃ¢ches)
- `fusion-tables` : INNER JOIN ERP + LIAISON + WEB
- `test-fusion` : Validation 714 lignes finales

### 3. Calcul CA (2 tÃ¢ches)
- `calcul-ca` : Calcul CA = price Ã— total_sales
- `test-ca` : Validation CA total = 70 568,60â‚¬

### 4. Identification vins premium (3 tÃ¢ches)
- `identification-premium` : Calcul z-score, sÃ©paration premium/ordinaires
- `test-premium` : Validation 30 vins premium (z-score > 2)
- `notification-succes` : Message de fin

---

## ğŸ§ª Tests automatisÃ©s

7 tests de validation avec alertes granulaires :

| Test | CritÃ¨re | Valeur attendue |
|------|---------|----------------|
| ERP | Absence doublons | 825 lignes |
| LIAISON | Absence doublons | 825 lignes |
| WEB clean | Suppression valeurs manquantes | 1428 lignes |
| WEB dedup | DÃ©doublonnage | 714 lignes |
| Fusion | CohÃ©rence volumÃ©trie | 714 lignes |
| CA | CohÃ©rence calcul | 70 568,60â‚¬ |
| Premium | CohÃ©rence z-score | 30 vins |

---

## ğŸ³ Docker

Image personnalisÃ©e `bottleneck-pipeline:latest` contenant :
- Python 3.11
- DuckDB 1.4.3
- pandas, openpyxl, scipy, pyyaml

**Build :**
```bash
docker build -t bottleneck-pipeline:latest .
```

---

## ğŸš€ DÃ©ploiement

### PrÃ©requis
- Docker Desktop installÃ© et dÃ©marrÃ©

### 1. Construire l'image Docker du pipeline
```bash
docker build -t bottleneck-pipeline:latest .
```

### 2. Lancer Kestra dans un container
```bash
docker run -d \
  --name kestra-server \
  --user root \
  -p 8080:8080 \
  -v /var/run/docker.sock:/var/run/docker.sock \
  kestra/kestra:latest \
  server local
```

**Note :** Kestra tourne dans un container Docker qui a accÃ¨s au socket Docker pour lancer d'autres containers (pour les tÃ¢ches du pipeline).

### 3. AccÃ©der Ã  l'interface Kestra
Ouvrir un navigateur : http://localhost:8080

### 4. Importer le workflow
1. Copier le contenu de `kestra/workflow.yaml`
2. CrÃ©er un nouveau flow dans Kestra
3. Coller le workflow

### 5. ExÃ©cuter le pipeline
1. Cliquer sur "Execute"
2. Uploader les 4 fichiers :
   - `data_bottleneck/erp.xlsx`
   - `data_bottleneck/liaison.xlsx`
   - `data_bottleneck/web.xlsx`
   - `config/test_config.yaml`
3. Lancer l'exÃ©cution
4. Suivre les logs en temps rÃ©el

---

## ğŸ“… Planification

**Trigger cron :** `0 9 15 * *`

ExÃ©cution automatique le **15 de chaque mois Ã  9h**

---

## ğŸ“ˆ RÃ©sultats

Le pipeline gÃ©nÃ¨re automatiquement :
- `rapport_ca.xlsx` : Chiffre d'affaires par produit
- `vins_premium.csv` : 30 vins avec z-score > 2
- `vins_ordinaires.csv` : 684 vins avec z-score â‰¤ 2

---

## ğŸ”§ DÃ©fis techniques

### Persistance des donnÃ©es
**ProblÃ¨me :** Chaque tÃ¢che Kestra s'exÃ©cute dans un container isolÃ© â†’ donnÃ©es perdues entre tÃ¢ches

**Solution :** Export/Import systÃ©matique en Parquet

### DÃ©doublonnage WEB
**ProblÃ¨me :** 3 SKU avec `total_sales` diffÃ©rents entre doublons

**Solution :** StratÃ©gie MAX (tri DESC + keep first)

### Tests granulaires
**ProblÃ¨me :** Alerte globale peu informative

**Solution :** 7 tests sÃ©parÃ©s = identification prÃ©cise des erreurs

---

## ğŸ”® AmÃ©liorations futures

- Notifications automatiques (email/Slack)
- Dashboard de monitoring (Grafana)
- Retry automatique en cas d'erreur
- Historisation mensuelle des donnÃ©es

---

## ğŸ‘¤ Auteur
Axelle 
Data Engineer - OpenClassrooms  
Projet P10 - [FÃ©v 2026]